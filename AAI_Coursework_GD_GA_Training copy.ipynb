{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>  *Hybrid Optimization for Training Neural Networks: Comparing Genetic Algorithms and Simulated Annealing in PyTorch for immage recognition* </center>\n",
    "\n",
    "### Abstract\n",
    "This is where my abstract will be\n",
    "\n",
    "### Introduction\n",
    "This will be the introduction for my coursework.\n",
    "\n",
    "### Learning objective\n",
    "This is where my abstract will be\n",
    "\n",
    "### Content\n",
    "This is where my abstract will be\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#set the optimisation criteria and the optimiser from Source [1]\n",
    "import torch.optim as optim\n",
    "\n",
    "import time\n",
    "\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Datasets\n",
    "\n",
    "The dataset used is the CIFAR10 for training.\n",
    "\n",
    "The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. <br>\n",
    "There are 50000 training images and 10000 test images.\n",
    "\n",
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CIFAR10 dataset\n",
    "\n",
    "# Load and normalise CIFAR10 dataset from Source [1]\n",
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "# Set the batch size for loading data\n",
    "batch_size = 4\n",
    "\n",
    "# Download and load the training dataset\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "# Download and load the test dataset\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "# Define the classes in the dataset\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "### End of source [1]\n",
    "\n",
    "# source [1] : https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to show image in the data set from Source [1]\n",
    "# functions to show an image\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "### end of source [1]\n",
    "\n",
    "#function that shows images with their labels\n",
    "def show_images_labels(images, labels):\n",
    "    imshow(torchvision.utils.make_grid(images))\n",
    "    print(' '.join(f'{classes[labels[j]]:5s}' for j in range(batch_size)))\n",
    "\n",
    "# get some random training images.\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "show_images_labels(images, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Base Model Implementation\n",
    "\n",
    "For our base neural network model we will be defining a CNN model ....\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CNN model from Source [2] modified so it can be used for CIFAR10 dataset\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.fc1 = nn.Linear(64 * 8 * 8, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = torch.max_pool2d(x, kernel_size=2, stride=2)\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = torch.max_pool2d(x, kernel_size=2, stride=2)\n",
    "        x = x.view(-1, 64 * 8 * 8)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return torch.log_softmax(x, dim=1)\n",
    "### End of source [2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_nn(model, trainloader, criterion, optimizer, epochs=2, use_gpu=True):\n",
    "    \"\"\"\n",
    "    Train a PyTorch neural network model efficiently.\n",
    "    \n",
    "    Args:\n",
    "        model: PyTorch model to train (updated in-place).\n",
    "        trainloader: DataLoader containing training data.\n",
    "        criterion: Loss function.\n",
    "        optimizer: Optimizer (Adam, SGD, etc.).\n",
    "        epochs (int, optional): Number of training epochs. Default is 2.\n",
    "        use_gpu (bool, optional): If True, enables GPU acceleration.\n",
    "\n",
    "    Returns:\n",
    "        train_losses: List of training losses over time.\n",
    "        training_time: Total time taken to train the model.\n",
    "    \"\"\"\n",
    "    # Use GPU if available and selected\n",
    "    device = torch.device(\"cuda\" if use_gpu and torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)  # Move model to GPU\n",
    "\n",
    "    model.train()  # Set model to training mode\n",
    "    train_losses = []\n",
    "\n",
    "    start_time = time.time()\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for i, (inputs, labels) in enumerate(trainloader, start=1):\n",
    "            # Move inputs and labels to the correct device (CPU/GPU)\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()  # Reset gradients\n",
    "\n",
    "            outputs = model(inputs)  # Forward pass\n",
    "            loss = criterion(outputs, labels)  # Compute loss\n",
    "\n",
    "            loss.backward()  # Backpropagation\n",
    "            optimizer.step()  # Update weights\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            # Log loss statistics every 2000 mini-batches\n",
    "            if i % 2000 == 0:\n",
    "                avg_loss = running_loss / 2000\n",
    "                train_losses.append(avg_loss)\n",
    "                running_loss = 0.0  # Reset running loss\n",
    "    end_time = time.time()\n",
    "\n",
    "    training_time = end_time - start_time\n",
    "    print('Finished Training')\n",
    "    return train_losses, training_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_4_random_images(testloader, model, classes, use_gpu=True):\n",
    "    \"\"\"\n",
    "    Visually tests the model on 4 random images from the test set and computes approximate accuracy.\n",
    "\n",
    "    Args:\n",
    "        testloader: PyTorch DataLoader for test data.\n",
    "        model: Trained PyTorch model.\n",
    "        classes: List of class labels.\n",
    "        use_gpu (bool, optional): Whether to use GPU if available.\n",
    "\n",
    "    Returns:\n",
    "        accuracy (float): Model accuracy on the 4 randomly selected images.\n",
    "    \"\"\"\n",
    "    device = torch.device(\"cuda\" if use_gpu and torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)  # Move model to GPU\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "\n",
    "    # Get a random batch from the testloader\n",
    "    dataiter = iter(testloader)\n",
    "    images, labels = next(dataiter)\n",
    "\n",
    "    # Select 4 random indices from the batch\n",
    "    indices = random.sample(range(len(images)), 4)\n",
    "    selected_images = images[indices]\n",
    "    selected_labels = labels[indices]\n",
    "\n",
    "    # Move data to GPU if available\n",
    "    selected_images, selected_labels = selected_images.to(device), selected_labels.to(device)\n",
    "\n",
    "    # Get model predictions\n",
    "    with torch.no_grad():\n",
    "        outputs = model(selected_images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "    # Compute accuracy\n",
    "    correct = (predicted == selected_labels).sum().item()\n",
    "    accuracy = correct / len(selected_labels) * 100\n",
    "\n",
    "    # Display images with labels\n",
    "    imshow(torchvision.utils.make_grid(selected_images.cpu()))  # Move images back to CPU for visualization\n",
    "    print('GroundTruth: ', ' '.join(f'{classes[selected_labels[j]]:5s}' for j in range(4)))\n",
    "    print('Predicted:   ', ' '.join(f'{classes[predicted[j]]:5s}' for j in range(4)))\n",
    "    print(f'Accuracy on these 4 images: {accuracy:.2f}%')\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_nn_per_class(testloader, model, classes, use_gpu=True):\n",
    "    \"\"\"\n",
    "    Efficiently tests the model on all images in the test set and returns per-class accuracy.\n",
    "\n",
    "    Args:\n",
    "        testloader: PyTorch DataLoader for test data.\n",
    "        model: Trained PyTorch model.\n",
    "        classes: List of class labels.\n",
    "        use_gpu (bool, optional): If True, uses GPU if available. Default is True.\n",
    "\n",
    "    Returns:\n",
    "        class_accuracies (dict): Dictionary containing accuracy for each class.\n",
    "    \"\"\"\n",
    "    # Select device (GPU if available, otherwise CPU)\n",
    "    device = torch.device(\"cuda\" if use_gpu and torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "\n",
    "    # Prepare to count predictions for each class\n",
    "    correct_pred = {classname: 0 for classname in classes}\n",
    "    total_pred = {classname: 0 for classname in classes}\n",
    "\n",
    "    # Disable gradient computation for efficiency\n",
    "    with torch.no_grad():\n",
    "        for images, labels in testloader:\n",
    "            images, labels = images.to(device), labels.to(device)  # Move data to GPU/CPU\n",
    "            outputs = model(images)\n",
    "            _, predictions = torch.max(outputs, 1)  # Get predicted class\n",
    "\n",
    "            # Update per-class statistics\n",
    "            for label, prediction in zip(labels, predictions):\n",
    "                total_pred[classes[label.item()]] += 1  # Count total instances of each class\n",
    "                if label == prediction:\n",
    "                    correct_pred[classes[label.item()]] += 1  # Count correct predictions\n",
    "\n",
    "    # Compute per-class accuracy\n",
    "    class_accuracies = {\n",
    "        classname: (100 * correct_pred[classname] / total_pred[classname]) if total_pred[classname] > 0 else 0.0\n",
    "        for classname in classes\n",
    "    }\n",
    "\n",
    "    print(\"Finished per-class testing.\")\n",
    "    return class_accuracies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_nn(testloader, model, use_gpu=True):\n",
    "    \"\"\"\n",
    "    Efficiently tests the model on all images in the test set and returns overall accuracy.\n",
    "\n",
    "    Args:\n",
    "        testloader: PyTorch DataLoader for test data.\n",
    "        model: Trained PyTorch model.\n",
    "        use_gpu (bool, optional): If True, uses GPU if available. Default is True.\n",
    "\n",
    "    Returns:\n",
    "        overall_accuracy (float): Accuracy of the model on the test set.\n",
    "    \"\"\"\n",
    "    # Select device (GPU if available, otherwise CPU)\n",
    "    device = torch.device(\"cuda\" if use_gpu and torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    # Disable gradient computation for efficiency\n",
    "    with torch.no_grad():\n",
    "        for images, labels in testloader:\n",
    "            images, labels = images.to(device), labels.to(device)  # Move data to GPU/CPU\n",
    "            outputs = model(images)\n",
    "            _, predictions = torch.max(outputs, 1)  # Get predicted class\n",
    "\n",
    "            # Update total and correct predictions\n",
    "            total += labels.size(0)\n",
    "            correct += (predictions == labels).sum().item()\n",
    "\n",
    "    # Compute overall accuracy\n",
    "    overall_accuracy = 100 * correct / total\n",
    "\n",
    "    print(f\"Overall Model Accuracy: {overall_accuracy:.2f}%\")\n",
    "    return overall_accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Genetic Algorithm Implementation\n",
    "\n",
    "<b> What is a Genetic algorithm?<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet5(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes, grayscale=False):\n",
    "        super(LeNet5, self).__init__()\n",
    "        \n",
    "        self.grayscale = grayscale\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        if self.grayscale:\n",
    "            in_channels = 1\n",
    "        else:\n",
    "            in_channels = 3\n",
    "\n",
    "        self.features = nn.Sequential(\n",
    "            \n",
    "            nn.Conv2d(in_channels, 6*in_channels, kernel_size=5),\n",
    "            nn.Tanh(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(6*in_channels, 16*in_channels, kernel_size=5),\n",
    "            nn.Tanh(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(16*5*5*in_channels, 120*in_channels),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(120*in_channels, 84*in_channels),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(84*in_channels, num_classes),\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        logits = self.classifier(x)\n",
    "        probas = F.softmax(logits, dim=1)\n",
    "        return logits, probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_fitness(model, optimizer, train_loader, test_loader,epochs):\n",
    "    criterion = nn.NLLLoss()\n",
    "    optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        for data, target in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    print('Finished Training')\n",
    "\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            output = model(data)\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            total += target.size(0)\n",
    "            correct += (predicted == target).sum().item()\n",
    "\n",
    "    accuracy = correct / total\n",
    "    print(f'Accuracy of the network on the 10000 test images: {100 * correct // total} %')\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write a function to initialise the population\n",
    "def initialise_population(population):\n",
    "    population = []\n",
    "    for _ in range(population_size):\n",
    "        model = CNN()\n",
    "        population.append(model)\n",
    "    return population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the function to perform the crossover operation\n",
    "def crossover(parent1, parent2):\n",
    "    child1 = CNN()\n",
    "    child2 = CNN()\n",
    "\n",
    "    child1.conv1.weight.data = torch.cat((parent1.conv1.weight.data[:16], parent2.conv1.weight.data[16:]), dim=0)\n",
    "    child2.conv1.weight.data = torch.cat((parent2.conv1.weight.data[:16], parent1.conv1.weight.data[16:]), dim=0)\n",
    "    return child1, child2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the function to perform the mutation operation\n",
    "def mutate(model, mutation_rate):\n",
    "    for param in model.parameters():\n",
    "        if torch.rand(1).item() < mutation_rate:\n",
    "            param.data += torch.randn(param.data.size()) * 0.1 # add random noise to the parameter\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #create a function that selects the tope best half of a population\n",
    "def select_best(population, fitness_scores):\n",
    "    best_half = []\n",
    "    for _ in range(population_size // 2):\n",
    "        index = fitness_scores.index(max(fitness_scores))\n",
    "        best_half.append(population[index])\n",
    "        fitness_scores[index] = 0\n",
    "    return best_half"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the population\n",
    "population = initialise_population(population_size)\n",
    "\n",
    "# Start Genetic Algorithm process\n",
    "for generation in range(generations):\n",
    "    print(f'Generation {generation + 1}')\n",
    "    best_accuracy = 0\n",
    "    best_model = None\n",
    "    fitness_scores = np.zeros(population_size)  # Preallocate array for fitness scores\n",
    "\n",
    "    # Start timer for the generation\n",
    "    start_time = time.time()\n",
    "\n",
    "    # **Optimized Parallel Fitness Evaluation**\n",
    "    for i, model in enumerate(population):\n",
    "        optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)  # Define optimizer for each model\n",
    "        fitness = compute_fitness(model, trainloader, testloader, epochs)\n",
    "        fitness_scores[i] = fitness\n",
    "        \n",
    "        if fitness > best_accuracy:\n",
    "            best_accuracy = fitness\n",
    "            best_model = model\n",
    "\n",
    "    # End timer for the generation\n",
    "    end_time = time.time()\n",
    "    generation_time = end_time - start_time\n",
    "\n",
    "    print(f'Best accuracy in generation {generation + 1} = {best_accuracy:.4f}')\n",
    "    print(f'Time taken for generation {generation + 1}: {generation_time:.2f} seconds')\n",
    "    print(\"\\n\")\n",
    "\n",
    "    # **Parent Selection**\n",
    "    top_indices = np.argsort(fitness_scores)[-population_size // 2:]  # Get indices of best half\n",
    "    selected_parents = [population[i] for i in top_indices]\n",
    "\n",
    "    next_generation = []\n",
    "\n",
    "    # **Crossover & Mutation**\n",
    "    for i in range(0, len(selected_parents), 2):\n",
    "        parent1 = selected_parents[i]\n",
    "        parent2 = selected_parents[i + 1]\n",
    "\n",
    "        # Perform crossover\n",
    "        child1, child2 = crossover(parent1, parent2)\n",
    "        \n",
    "        # Apply mutation\n",
    "        mutate(child1, mutation_rate)\n",
    "        mutate(child2, mutation_rate)\n",
    "\n",
    "        next_generation.append(child1)\n",
    "        next_generation.append(child2)\n",
    "\n",
    "    # **Efficient Population Update**\n",
    "    population = next_generation[:population_size]  # Ensure population size remains constant\n",
    "\n",
    "# **Evaluate Final Best Model**\n",
    "print(\"Best model's accuracy:\")\n",
    "final_accuracy = test_nn(testloader, best_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # execute the genetic algorithm\n",
    "# population = initialise_population(population_size)\n",
    "\n",
    "# for generation in range(generations):\n",
    "#     print(f'Generation {generation + 1}')\n",
    "#     best_accuracy = 0\n",
    "#     best_model = None\n",
    "#     fitness_scores = []\n",
    "\n",
    "#     # Start timer for the generation\n",
    "#     start_time = time.time()\n",
    "\n",
    "#     # Compute the fitness of the population\n",
    "#     for model in population:\n",
    "#         optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)  # Define optimizer for each model\n",
    "#         fitness = compute_fitness(model, trainloader, testloader, epochs)\n",
    "        \n",
    "#         if fitness > best_accuracy:\n",
    "#             best_accuracy = fitness\n",
    "#             best_model = model\n",
    "        \n",
    "#         fitness_scores.append(fitness)\n",
    "\n",
    "#     # End timer for the generation\n",
    "#     end_time = time.time()\n",
    "#     generation_time = end_time - start_time\n",
    "\n",
    "#     print(f'Best accuracy in generation {generation + 1} = {best_accuracy}')\n",
    "#     print(f'Time taken for generation {generation + 1}: {generation_time:.2f} seconds')\n",
    "#     print(\"\\n\")\n",
    "\n",
    "#     next_generation = []\n",
    "\n",
    "#     # Select the top half of the population\n",
    "#     selected_parents = select_best(population, fitness_scores)\n",
    "\n",
    "#     # Crossover and mutate the parents\n",
    "#     for i in range(0, len(selected_parents), 2):\n",
    "#         parent1 = selected_parents[i]\n",
    "#         parent2 = selected_parents[i + 1]\n",
    "#         child1, child2 = crossover(parent1, parent2)\n",
    "#         child1 = mutate(child1, mutation_rate)\n",
    "#         child2 = mutate(child2, mutation_rate)\n",
    "#         next_generation.append(child1)\n",
    "#         next_generation.append(child2)\n",
    "\n",
    "#     # Update the population with the next generation\n",
    "#     population = next_generation\n",
    "\n",
    "# # Print the best performing model\n",
    "# print(\"Best model's accuracy:\")\n",
    "# print(test_all_images(testloader, best_model))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the best model\n",
    "torch.save(best_model.state_dict(), 'best_model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Simulated Annealing Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulated Annealing Hyperparameters\n",
    "initial_temp = 10.0  # Initial temperature\n",
    "final_temp = 0.1  # Stopping temperature\n",
    "alpha = 0.95  # Cooling rate\n",
    "max_iterations = 100  # Number of iterations per temperature step\n",
    "\n",
    "model = CNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #function to compute loss\n",
    "# def compute_loss(model, dataloader):\n",
    "#     model.eval()\n",
    "#     loss = 0\n",
    "#     with torch.no_grad():\n",
    "#         for data, target in dataloader:\n",
    "#             output = model(data)\n",
    "#             loss += criterion(output, target).item()\n",
    "#     return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import copy\n",
    "\n",
    "# def simulated_annealing(model, dataloader, initial_temp, final_temp, alpha, max_iterations):\n",
    "#     \"\"\"\n",
    "#     Simulated Annealing Algorithm for optimizing neural network weights.\n",
    "\n",
    "#     Args:\n",
    "#         model: PyTorch model to optimize.\n",
    "#         dataloader: DataLoader for evaluating loss.\n",
    "#         initial_temp: Initial temperature (controls acceptance of bad moves).\n",
    "#         final_temp: Final temperature to stop SA.\n",
    "#         alpha: Cooling rate (0 < alpha < 1).\n",
    "#         max_iterations: Number of iterations per temperature step.\n",
    "\n",
    "#     Returns:\n",
    "#         best_model: The model with the lowest observed loss.\n",
    "#     \"\"\"\n",
    "#     best_model = copy.deepcopy(model)\n",
    "#     current_model = copy.deepcopy(model)\n",
    "#     current_loss = compute_loss(current_model, dataloader)\n",
    "#     best_loss = current_loss  # Store best loss for efficiency\n",
    "\n",
    "#     temp = initial_temp\n",
    "#     iteration = 0\n",
    "\n",
    "#     while temp > final_temp:\n",
    "#         for _ in range(max_iterations):\n",
    "#             # Generate a new model with slight random weight changes\n",
    "#             new_model = copy.deepcopy(current_model)\n",
    "#             with torch.no_grad():\n",
    "#                 for param in new_model.parameters():\n",
    "#                     perturbation = torch.randn_like(param) * (temp / initial_temp)  # Scale perturbation\n",
    "#                     param += perturbation  # Apply perturbation\n",
    "\n",
    "#             # Compute new loss\n",
    "#             new_loss = compute_loss(new_model, dataloader)\n",
    "\n",
    "#             # Accept new model if loss is lower or with a probability P\n",
    "#             delta = new_loss - current_loss\n",
    "#             if delta < 0 or np.exp(-delta / temp) > np.random.rand():\n",
    "#                 current_model = new_model\n",
    "#                 current_loss = new_loss\n",
    "\n",
    "#                 # Update best model if improved\n",
    "#                 if new_loss < best_loss:\n",
    "#                     best_model = copy.deepcopy(new_model)\n",
    "#                     best_loss = new_loss\n",
    "\n",
    "#         # Reduce temperature\n",
    "#         temp *= alpha\n",
    "#         iteration += 1\n",
    "#         print(f\"Iteration {iteration}: Temperature {temp:.4f}, Loss {current_loss:.4f}\")\n",
    "\n",
    "#     return best_model\n",
    "\n",
    "# # Run Simulated Annealing on CNN\n",
    "# best_trained_model = simulated_annealing(model, trainloader, initial_temp=10.0, final_temp=0.1, alpha=0.95, max_iterations=10)\n",
    "\n",
    "# print(test_all_images(testloader, best_trained_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Evaluation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function will be used to evaluate the network.\n",
    "def evaluate_model(model, trainloader, testloader, classes, epochs=10, use_gpu=True, show_graph=True):\n",
    "    \"\"\"\n",
    "    Trains and evaluates a PyTorch model while tracking losses and accuracies.\n",
    "\n",
    "    Args:\n",
    "        model: PyTorch model to train and evaluate.\n",
    "        trainloader: DataLoader containing training data.\n",
    "        testloader: DataLoader containing test data.\n",
    "        classes: List of class labels.\n",
    "        epochs (int, optional): Number of training epochs. Default is 10.\n",
    "        use_gpu (bool, optional): If True, enables GPU acceleration. Default is True.\n",
    "        show_graph (bool, optional): If True, displays accuracy/loss graphs. Default is True.\n",
    "\n",
    "    Returns:\n",
    "        results (dict): Dictionary containing:\n",
    "            - 'train_losses': List of training losses.\n",
    "            - 'train_accuracies': List of training accuracies.\n",
    "            - 'test_accuracies': List of test accuracies.\n",
    "            - 'test_class_accuracies': Dictionary of per-class accuracy.\n",
    "            - 'final_test_accuracy': Final overall test accuracy.\n",
    "            - 'total_time': Total time taken for training.\n",
    "    \"\"\"\n",
    "    # Specify the loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimiser = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "    # Move model to GPU if available\n",
    "    device = torch.device(\"cuda\" if use_gpu and torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    # Initialize tracking variables\n",
    "    train_losses = []\n",
    "    train_accuracies = []\n",
    "    test_accuracies = []\n",
    "\n",
    "    total_time = 0\n",
    "\n",
    "    # Training and Evaluation Loop\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"\\nEpoch {epoch+1}/{epochs}\")\n",
    "\n",
    "        # Train the model for one epoch\n",
    "        train_loss, train_time = train_nn(model, trainloader, criterion, optimiser, epochs=1, use_gpu=use_gpu)\n",
    "        total_time += train_time\n",
    "\n",
    "        # Test the model after training\n",
    "        test_accuracy = test_nn(testloader, model, classes, use_gpu=use_gpu)\n",
    "\n",
    "        # Store losses and accuracies\n",
    "        train_losses.append(train_loss[-1])  # Store the last batch loss of the epoch\n",
    "        train_accuracies.append(test_accuracy)  # Approximate training accuracy\n",
    "        test_accuracies.append(test_accuracy)\n",
    "\n",
    "        print(f'Epoch {epoch+1}: Train Loss: {train_loss[-1]:.4f}, Test Accuracy: {test_accuracy:.2f}%')\n",
    "\n",
    "    # Final test accuracy after all epochs\n",
    "    final_test_accuracy = test_accuracies[-1]\n",
    "\n",
    "    # final test acuracy per class\n",
    "    test_class_accuracies = test_nn_per_class(testloader, model, classes, use_gpu=use_gpu)\n",
    "\n",
    "    \n",
    "    if show_graph:\n",
    "        # Plot training vs testing accuracy if enabled\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.plot(range(1, epochs+1), train_accuracies, label='Train Accuracy')\n",
    "        plt.plot(range(1, epochs+1), test_accuracies, label='Test Accuracy')\n",
    "        plt.title('Training vs Testing Accuracy')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Accuracy (%)')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "        #plot the loss curve over time as the model trained\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.plot(train_losses, label='Training Loss', color='blue')\n",
    "        plt.xlabel('Batch (x2000)')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.title('Training Loss Over Time')\n",
    "        plt.legend()\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()       \n",
    "\n",
    "        # Plot per-class accuracy if enabled\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.bar(test_class_accuracies.keys(), test_class_accuracies.values(), color='blue')\n",
    "        plt.xlabel(\"Classes\")\n",
    "        plt.ylabel(\"Accuracy (%)\")\n",
    "        plt.title(\"Model Accuracy Per Class\")\n",
    "        plt.xticks(rotation=45)  # Rotate class names for readability\n",
    "        plt.ylim(0, 100)  # Set y-axis range to 0-100%\n",
    "        plt.show()\n",
    "\n",
    "        # print per-class accuracy\n",
    "        for classname, accuracy in test_class_accuracies():\n",
    "            print(f'Accuracy for class {classname:5s}: {accuracy:.1f}%')\n",
    "\n",
    "    # Return all results in a dictionary\n",
    "    results = {\n",
    "        \"train_losses\": train_losses,\n",
    "        \"train_accuracies\": train_accuracies,\n",
    "        \"test_accuracies\": test_accuracies,\n",
    "        \"test_class_accuracies\": test_class_accuracies,\n",
    "        \"final_test_accuracy\": final_test_accuracy,\n",
    "        \"total_time\": total_time\n",
    "    }\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Comparitive Analysis and Results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base model results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model, optimizer, and loss function\n",
    "base = CNN()\n",
    "optimizer = optim.Adam(base.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Train on GPU with AMP\n",
    "trained_model, losses = train_nn(base, trainloader, criterion, optimizer, epochs=5, stats=True, graph=True, use_gpu=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Genetic algorithm results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the number of generations\n",
    "generations = 2\n",
    "\n",
    "# Set the population size\n",
    "population_size = generations * 2\n",
    "\n",
    "# Set the mutation rate\n",
    "mutation_rate = 0.1\n",
    "\n",
    "# Set the number of epochs\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulated anealing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Hybrid Training Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Ensamble learinging Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Conclusion\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## References\n",
    "\n",
    "\n",
    "source [1] : https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html \n",
    "source [2] : https://www.geeksforgeeks.org/how-to-implement-genetic-algorithm-using-pytorch/ "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
