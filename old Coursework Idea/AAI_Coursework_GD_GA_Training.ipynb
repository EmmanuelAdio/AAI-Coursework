{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>  *Training different CNN model achitecture using genetic algorithms for image processessing* </center>\n",
    "\n",
    "---\n",
    "\n",
    "### Abstract\n",
    "Train different CNN model achitectures using the genetic algorithm and then ensambling the best models from ech generation to make a super model, for image classifaction on the CIFAR-10 dataset.\n",
    "\n",
    "### Introduction\n",
    "This will be the introduction for my coursework.\n",
    "\n",
    "### Learning objective\n",
    "This is where my abstract will be\n",
    "\n",
    "### Content\n",
    "This is where my abstract will be\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import time\n",
    "\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Dataset\n",
    "\n",
    "The dataset used is the CIFAR10 for training.\n",
    "\n",
    "The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. <br>\n",
    "There are 50000 training images and 10000 test images.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "#CIFAR10 dataset\n",
    "\n",
    "# Load and normalise CIFAR10 dataset from Source [1]\n",
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "# Set the batch size for loading data\n",
    "batch_size = 4\n",
    "\n",
    "# Download and load the training dataset\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "# Download and load the test dataset\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "# Define the classes in the dataset\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "### End of source [1]\n",
    "\n",
    "# source [1] : https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#function that shows images with their labels\n",
    "def show_images_labels(images, labels):\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    for i in range(4):\n",
    "        plt.subplot(2, 5, i + 1)\n",
    "        img = images[i] / 2 + 0.5  # unnormalize\n",
    "        npimg = img.numpy()\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "        plt.title(f\"{classes[labels[i]]}\")\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# get some random training images.\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "show_images_labels(images, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Base Model Implementation\n",
    "\n",
    "For our base neural network model we will be defining a CNN model ....\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CNN model from Source [2] modified so it can be used for CIFAR10 dataset\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.fc1 = nn.Linear(64 * 8 * 8, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = torch.max_pool2d(x, kernel_size=2, stride=2)\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = torch.max_pool2d(x, kernel_size=2, stride=2)\n",
    "        x = x.view(-1, 64 * 8 * 8)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return torch.log_softmax(x, dim=1)\n",
    "### End of source [2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet5(nn.Module):\n",
    "    def __init__(self, num_classes, grayscale=False):\n",
    "        super(LeNet5, self).__init__()\n",
    "        \n",
    "        self.grayscale = grayscale\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        if self.grayscale:\n",
    "            in_channels = 1\n",
    "        else:\n",
    "            in_channels = 3\n",
    "\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 6*in_channels, kernel_size=5),\n",
    "            nn.Tanh(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(6*in_channels, 16*in_channels, kernel_size=5),\n",
    "            nn.Tanh(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(16*5*5*in_channels, 120*in_channels),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(120*in_channels, 84*in_channels),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(84*in_channels, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        logits = self.classifier(x)\n",
    "        probas = F.softmax(logits, dim=1)\n",
    "        return logits, probas\n",
    "\n",
    "# Modify the crossover function to handle LeNet5\n",
    "def crossover(parent1, parent2):\n",
    "    child1 = LeNet5(num_classes=10)\n",
    "    child2 = LeNet5(num_classes=10)\n",
    "\n",
    "    # Perform crossover on the convolutional layers\n",
    "    child1.features[0].weight.data = torch.cat((parent1.features[0].weight.data[:3], parent2.features[0].weight.data[3:]), dim=0)\n",
    "    child2.features[0].weight.data = torch.cat((parent2.features[0].weight.data[:3], parent1.features[0].weight.data[3:]), dim=0)\n",
    "\n",
    "    # Perform crossover on the fully connected layers\n",
    "    child1.classifier[0].weight.data = torch.cat((parent1.classifier[0].weight.data[:60], parent2.classifier[0].weight.data[60:]), dim=0)\n",
    "    child2.classifier[0].weight.data = torch.cat((parent2.classifier[0].weight.data[:60], parent1.classifier[0].weight.data[60:]), dim=0)\n",
    "\n",
    "    return child1, child2\n",
    "\n",
    "# Modify the mutation function to handle LeNet5\n",
    "def mutate(model, mutation_rate):\n",
    "    for param in model.parameters():\n",
    "        if torch.rand(1).item() < mutation_rate:\n",
    "            param.data += torch.randn(param.data.size()) * 0.1  # add random noise to the parameter\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_nn_lenet(model, trainloader, criterion, optimizer, epochs=2, use_gpu=True):\n",
    "    \"\"\"\n",
    "    Train a PyTorch neural network model efficiently.\n",
    "    \n",
    "    Args:\n",
    "        model: PyTorch model to train (updated in-place).\n",
    "        trainloader: DataLoader containing training data.\n",
    "        criterion: Loss function.\n",
    "        optimizer: Optimizer (Adam, SGD, etc.).\n",
    "        epochs (int, optional): Number of training epochs. Default is 2.\n",
    "        use_gpu (bool, optional): If True, enables GPU acceleration.\n",
    "\n",
    "    Returns:\n",
    "        train_losses: List of training losses over time.\n",
    "        training_time: Total time taken to train the model.\n",
    "    \"\"\"\n",
    "    # Use GPU if available and selected\n",
    "    device = torch.device(\"cuda\" if use_gpu and torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)  # Move model to GPU\n",
    "\n",
    "    model.train()  # Set model to training mode\n",
    "    train_losses = []\n",
    "\n",
    "    start_time = time.time()\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for i, (inputs, labels) in enumerate(trainloader, start=1):\n",
    "            # Move inputs and labels to the correct device (CPU/GPU)\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            ### FORWARD AND BACK PROP\n",
    "            logits, probas = model(inputs)\n",
    "            loss = F.cross_entropy(logits, labels)\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            loss.backward()\n",
    "            \n",
    "            ### UPDATE MODEL PARAMETERS\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            # Log loss statistics every 2000 mini-batches\n",
    "            if i % 2000 == 0:\n",
    "                avg_loss = running_loss / 2000\n",
    "                print(f'Epoch: {epoch}, Batch: {i}, Avg. Loss: {avg_loss:.4f}')\n",
    "                train_losses.append(avg_loss)\n",
    "                running_loss = 0.0  # Reset running loss\n",
    "    end_time = time.time()\n",
    "\n",
    "    training_time = end_time - start_time\n",
    "    print('Finished Training')\n",
    "    return train_losses, training_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_nn_lenet(model, data_loader, use_gpu=True):\n",
    "    \"\"\"\n",
    "    Efficiently tests the LeNet model on all images in the data loader and returns overall accuracy.\n",
    "\n",
    "    Args:\n",
    "        data_loader: PyTorch DataLoader for test data.\n",
    "        model: Trained PyTorch model.\n",
    "        use_gpu (bool, optional): If True, uses GPU if available. Default is True.\n",
    "\n",
    "    Returns:\n",
    "        overall_accuracy (float): Accuracy of the model on the data loader.\n",
    "    \"\"\"\n",
    "    # Select device (GPU if available, otherwise CPU)\n",
    "    device = torch.device(\"cuda\" if use_gpu and torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    # Disable gradient computation for efficiency\n",
    "    with torch.no_grad():\n",
    "        for features, targets in data_loader:\n",
    "            features, targets = features.to(device), targets.to(device)  # Move data to GPU/CPU\n",
    "            logits, probas = model(features)\n",
    "            _, predicted_labels = torch.max(probas, 1)  # Get predicted class\n",
    "\n",
    "            # Update total and correct predictions\n",
    "            total += targets.size(0)\n",
    "            correct += (predicted_labels == targets).sum().item()\n",
    "\n",
    "    # Compute overall accuracy\n",
    "    overall_accuracy = 100 * correct / total\n",
    "\n",
    "    print(f\"Overall Model Accuracy: {overall_accuracy:.2f}%\")\n",
    "    return overall_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_nn(model, trainloader, criterion, optimizer, epochs=2, use_gpu=True):\n",
    "    \"\"\"\n",
    "    Train a PyTorch neural network model efficiently.\n",
    "    \n",
    "    Args:\n",
    "        model: PyTorch model to train (updated in-place).\n",
    "        trainloader: DataLoader containing training data.\n",
    "        criterion: Loss function.\n",
    "        optimizer: Optimizer (Adam, SGD, etc.).\n",
    "        epochs (int, optional): Number of training epochs. Default is 2.\n",
    "        use_gpu (bool, optional): If True, enables GPU acceleration.\n",
    "\n",
    "    Returns:\n",
    "        train_losses: List of training losses over time.\n",
    "        training_time: Total time taken to train the model.\n",
    "    \"\"\"\n",
    "    # Use GPU if available and selected\n",
    "    device = torch.device(\"cuda\" if use_gpu and torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)  # Move model to GPU\n",
    "\n",
    "    model.train()  # Set model to training mode\n",
    "    train_losses = []\n",
    "\n",
    "    start_time = time.time()\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for i, (inputs, labels) in enumerate(trainloader, start=1):\n",
    "            # Move inputs and labels to the correct device (CPU/GPU)\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()  # Reset gradients\n",
    "\n",
    "            outputs = model(inputs)  # Forward pass\n",
    "            loss = criterion(outputs, labels)  # Compute loss\n",
    "\n",
    "            loss.backward()  # Backpropagation\n",
    "            optimizer.step()  # Update weights\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            # Log loss statistics every 2000 mini-batches\n",
    "            if i % 2000 == 0:\n",
    "                avg_loss = running_loss / 2000\n",
    "                train_losses.append(avg_loss)\n",
    "                running_loss = 0.0  # Reset running loss\n",
    "    end_time = time.time()\n",
    "\n",
    "    training_time = end_time - start_time\n",
    "    print('Finished Training')\n",
    "    return train_losses, training_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_nn(testloader, model, use_gpu=True):\n",
    "    \"\"\"\n",
    "    Efficiently tests the model on all images in the test set and returns overall accuracy.\n",
    "\n",
    "    Args:\n",
    "        testloader: PyTorch DataLoader for test data.\n",
    "        model: Trained PyTorch model.\n",
    "        use_gpu (bool, optional): If True, uses GPU if available. Default is True.\n",
    "\n",
    "    Returns:\n",
    "        overall_accuracy (float): Accuracy of the model on the test set.\n",
    "    \"\"\"\n",
    "    # Select device (GPU if available, otherwise CPU)\n",
    "    device = torch.device(\"cuda\" if use_gpu and torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    # Disable gradient computation for efficiency\n",
    "    with torch.no_grad():\n",
    "        for images, labels in testloader:\n",
    "            images, labels = images.to(device), labels.to(device)  # Move data to GPU/CPU\n",
    "            outputs = model(images)\n",
    "            _, predictions = torch.max(outputs, 1)  # Get predicted class\n",
    "\n",
    "            # Update total and correct predictions\n",
    "            total += labels.size(0)\n",
    "            correct += (predictions == labels).sum().item()\n",
    "\n",
    "    # Compute overall accuracy\n",
    "    overall_accuracy = 100 * correct / total\n",
    "\n",
    "    print(f\"Overall Model Accuracy: {overall_accuracy:.2f}%\")\n",
    "    return overall_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_4_random_images(testloader, model, classes, use_gpu=True):\n",
    "    \"\"\"\n",
    "    Visually tests the model on 4 random images from the test set and computes approximate accuracy.\n",
    "\n",
    "    Args:\n",
    "        testloader: PyTorch DataLoader for test data.\n",
    "        model: Trained PyTorch model.\n",
    "        classes: List of class labels.\n",
    "        use_gpu (bool, optional): Whether to use GPU if available.\n",
    "\n",
    "    Returns:\n",
    "        accuracy (float): Model accuracy on the 4 randomly selected images.\n",
    "    \"\"\"\n",
    "    device = torch.device(\"cuda\" if use_gpu and torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)  # Move model to GPU\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "\n",
    "    # Get a random batch from the testloader\n",
    "    dataiter = iter(testloader)\n",
    "    images, labels = next(dataiter)\n",
    "\n",
    "    # Select 4 random indices from the batch\n",
    "    indices = random.sample(range(len(images)), 4)\n",
    "    selected_images = images[indices]\n",
    "    selected_labels = labels[indices]\n",
    "\n",
    "    # Move data to GPU if available\n",
    "    selected_images, selected_labels = selected_images.to(device), selected_labels.to(device)\n",
    "\n",
    "    # Get model predictions\n",
    "    with torch.no_grad():\n",
    "        outputs = model(selected_images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "    # Compute accuracy\n",
    "    correct = (predicted == selected_labels).sum().item()\n",
    "    accuracy = correct / len(selected_labels) * 100\n",
    "\n",
    "    # Display images with labels and predictions\n",
    "    show_images_labels(selected_images.cpu(), selected_labels.cpu())\n",
    "    print('Predicted:   ', ' '.join(f'{classes[predicted[j]]:5s}' for j in range(4)))\n",
    "    print(f'Accuracy on these 4 images: {accuracy:.2f}%')\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_nn_per_class(testloader, model, classes, use_gpu=True):\n",
    "    \"\"\"\n",
    "    Efficiently tests the model on all images in the test set and returns per-class accuracy.\n",
    "\n",
    "    Args:\n",
    "        testloader: PyTorch DataLoader for test data.\n",
    "        model: Trained PyTorch model.\n",
    "        classes: List of class labels.\n",
    "        use_gpu (bool, optional): If True, uses GPU if available. Default is True.\n",
    "\n",
    "    Returns:\n",
    "        class_accuracies (dict): Dictionary containing accuracy for each class.\n",
    "    \"\"\"\n",
    "    # Select device (GPU if available, otherwise CPU)\n",
    "    device = torch.device(\"cuda\" if use_gpu and torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "\n",
    "    # Prepare to count predictions for each class\n",
    "    correct_pred = {classname: 0 for classname in classes}\n",
    "    total_pred = {classname: 0 for classname in classes}\n",
    "\n",
    "    # Disable gradient computation for efficiency\n",
    "    with torch.no_grad():\n",
    "        for images, labels in testloader:\n",
    "            images, labels = images.to(device), labels.to(device)  # Move data to GPU/CPU\n",
    "            outputs = model(images)\n",
    "            _, predictions = torch.max(outputs, 1)  # Get predicted class\n",
    "\n",
    "            # Update per-class statistics\n",
    "            for label, prediction in zip(labels, predictions):\n",
    "                total_pred[classes[label.item()]] += 1  # Count total instances of each class\n",
    "                if label == prediction:\n",
    "                    correct_pred[classes[label.item()]] += 1  # Count correct predictions\n",
    "\n",
    "    # Compute per-class accuracy\n",
    "    class_accuracies = {\n",
    "        classname: (100 * correct_pred[classname] / total_pred[classname]) if total_pred[classname] > 0 else 0.0\n",
    "        for classname in classes\n",
    "    }\n",
    "\n",
    "    print(\"Finished per-class testing.\")\n",
    "    return class_accuracies\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Genetic Algorithm Implementation\n",
    "\n",
    "<b> What is a Genetic algorithm?<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_fitness(criterion, model, optimizer, trainloader, testloader,epochs):\n",
    "    # Train the model\n",
    "    train_nn(model, trainloader, criterion, optimizer, epochs)\n",
    "\n",
    "    # test the model.\n",
    "    test_accuracy = test_nn(testloader, model)\n",
    "    return test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write a function to initialise the population\n",
    "def initialise_population(population_size):\n",
    "    population = []\n",
    "    for _ in range(population_size):\n",
    "        model = CNN()\n",
    "        population.append(model)\n",
    "    return population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the function to perform the crossover operation\n",
    "def crossover(parent1, parent2):\n",
    "    child1 = CNN()\n",
    "    child2 = CNN()\n",
    "\n",
    "    child1.conv1.weight.data = torch.cat((parent1.conv1.weight.data[:16], parent2.conv1.weight.data[16:]), dim=0)\n",
    "    child2.conv1.weight.data = torch.cat((parent2.conv1.weight.data[:16], parent1.conv1.weight.data[16:]), dim=0)\n",
    "    return child1, child2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the function to perform the mutation operation\n",
    "def mutate(model, mutation_rate):\n",
    "    for param in model.parameters():\n",
    "        if torch.rand(1).item() < mutation_rate:\n",
    "            param.data += torch.randn(param.data.size()) * 0.1 # add random noise to the parameter\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_genetic_algorithm(criterion, population_size, generations, trainloader, testloader, epochs, mutation_rate):\n",
    "    \"\"\"\n",
    "    Runs a Genetic Algorithm (GA) to optimize a neural network model.\n",
    "\n",
    "    Args:\n",
    "        population_size (int): Number of models in the population.\n",
    "        generations (int): Number of generations to evolve.\n",
    "        trainloader: PyTorch DataLoader for training data.\n",
    "        testloader: PyTorch DataLoader for test data.\n",
    "        epochs (int): Number of epochs for fitness evaluation.\n",
    "        mutation_rate (float): Probability of mutation.\n",
    "\n",
    "    Returns:\n",
    "        results (dict): Dictionary containing:\n",
    "            - 'best_model': Best model from the final generation.\n",
    "            - 'generation_times': List of time taken for each generation.\n",
    "            - 'best_accuracies': List of best accuracies from each generation.\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    # Initialize the population\n",
    "    population = initialise_population(population_size)\n",
    "\n",
    "    # Tracking metrics\n",
    "    generation_times = []\n",
    "    best_accuracies = []\n",
    "\n",
    "    # Start Genetic Algorithm process\n",
    "    for generation in range(generations):\n",
    "        print(f\"\\nGeneration {generation + 1}\")\n",
    "\n",
    "        best_accuracy = 0\n",
    "        best_model = None\n",
    "        fitness_scores = np.zeros(population_size)  # Preallocate array for fitness scores\n",
    "\n",
    "        # Start timer for the generation\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Evaluate fitness for each model\n",
    "        for i, model in enumerate(population):\n",
    "            optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)  # Define optimizer\n",
    "            fitness = compute_fitness(criterion, model, optimizer, trainloader, testloader,epochs)\n",
    "            fitness_scores[i] = fitness\n",
    "\n",
    "            if fitness > best_accuracy:\n",
    "                best_accuracy = fitness\n",
    "                best_model = model\n",
    "\n",
    "        # End timer for the generation\n",
    "        end_time = time.time()\n",
    "        generation_time = end_time - start_time\n",
    "\n",
    "        # Store time and best accuracy for visualization\n",
    "        generation_times.append(generation_time)\n",
    "        best_accuracies.append(best_accuracy)\n",
    "\n",
    "        print(f'Best accuracy in generation {generation + 1} = {best_accuracy:.4f}')\n",
    "        print(f'Time taken for generation {generation + 1}: {generation_time:.2f} seconds')\n",
    "\n",
    "        # **Parent Selection**\n",
    "        top_indices = np.argsort(fitness_scores)[-population_size // 2:]  # Get top 50%\n",
    "        selected_parents = [population[i] for i in top_indices]\n",
    "\n",
    "        next_generation = []\n",
    "\n",
    "        # **Crossover & Mutation**\n",
    "        for i in range(0, len(selected_parents), 2):\n",
    "            parent1 = selected_parents[i]\n",
    "            parent2 = selected_parents[i + 1]\n",
    "\n",
    "            # Perform crossover\n",
    "            child1, child2 = crossover(parent1, parent2)\n",
    "\n",
    "            # Apply mutation\n",
    "            mutate(child1, mutation_rate)\n",
    "            mutate(child2, mutation_rate)\n",
    "\n",
    "            next_generation.append(child1)\n",
    "            next_generation.append(child2)\n",
    "\n",
    "        # Ensure the population size remains constant\n",
    "        population = next_generation[:population_size]\n",
    "\n",
    "    # **Return the best model and collected data for visualization**\n",
    "    results = {\n",
    "        \"best_model\": best_model,\n",
    "        \"generation_times\": generation_times,\n",
    "        \"best_accuracies\": best_accuracies\n",
    "    }\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Evaluation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function will be used to evaluate the network.\n",
    "def evaluate_model(model, trainloader, testloader, classes, epochs=5, use_gpu=True, show_graph=True, tain = True):\n",
    "    \"\"\"\n",
    "    Trains and evaluates a PyTorch model while tracking losses and accuracies.\n",
    "\n",
    "    Args:\n",
    "        model: PyTorch model to train and evaluate.\n",
    "        trainloader: DataLoader containing training data.\n",
    "        testloader: DataLoader containing test data.\n",
    "        classes: List of class labels.\n",
    "        epochs (int, optional): Number of training epochs. Default is 10.\n",
    "        use_gpu (bool, optional): If True, enables GPU acceleration. Default is True.\n",
    "        show_graph (bool, optional): If True, displays accuracy/loss graphs. Default is True.\n",
    "\n",
    "    Returns:\n",
    "        results (dict): Dictionary containing:\n",
    "            - 'train_losses': List of training losses.\n",
    "            - 'train_accuracies': List of training accuracies.\n",
    "            - 'test_accuracies': List of test accuracies.\n",
    "            - 'test_class_accuracies': Dictionary of per-class accuracy.\n",
    "            - 'final_test_accuracy': Final overall test accuracy.\n",
    "            - 'total_time': Total time taken for training.\n",
    "    \"\"\"\n",
    "    # Specify the loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimiser = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "    # Move model to GPU if available\n",
    "    device = torch.device(\"cuda\" if use_gpu and torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    # Initialize tracking variables\n",
    "    train_losses = []\n",
    "    train_accuracies = []\n",
    "    test_accuracies = []\n",
    "\n",
    "    total_time = 0\n",
    "\n",
    "    if tain:\n",
    "        # Training and Evaluation Loop\n",
    "        for epoch in range(epochs):\n",
    "            print(f\"\\nEpoch {epoch+1}/{epochs}\")\n",
    "\n",
    "            # Train the model for one epoch\n",
    "            train_loss, train_time = train_nn(model, trainloader, criterion, optimiser, epochs=1, use_gpu=use_gpu)\n",
    "            total_time += train_time\n",
    "\n",
    "            # Test the model after training\n",
    "            test_accuracy = test_nn(testloader, model, use_gpu=use_gpu)\n",
    "\n",
    "            # Store losses and accuracies\n",
    "            train_losses.append(train_loss[-1])  # Store the last batch loss of the epoch\n",
    "            train_accuracies.append(test_nn(trainloader, model, use_gpu=use_gpu))\n",
    "            test_accuracies.append(test_accuracy)\n",
    "\n",
    "            print(f'Epoch {epoch+1}: Train Loss: {train_loss[-1]:.4f}, Test Accuracy: {test_accuracy:.2f}%')\n",
    "        \n",
    "        # Final test accuracy after all epochs\n",
    "        final_test_accuracy = test_accuracies[-1]\n",
    "    else:\n",
    "        final_test_accuracy = test_nn(testloader, model, use_gpu=use_gpu)\n",
    "\n",
    "\n",
    "    # final test acuracy per class\n",
    "    test_class_accuracies = test_nn_per_class(testloader, model, classes, use_gpu=use_gpu)\n",
    "\n",
    "    if show_graph:\n",
    "        if tain:\n",
    "            # Plot training vs testing accuracy if enabled\n",
    "            plt.figure(figsize=(12, 6))\n",
    "            plt.plot(range(1, epochs+1), train_accuracies, label='Train Accuracy')\n",
    "            plt.plot(range(1, epochs+1), test_accuracies, label='Test Accuracy')\n",
    "            plt.title('Training vs Testing Accuracy')\n",
    "            plt.xlabel('Epochs')\n",
    "            plt.ylabel('Accuracy (%)')\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            plt.show()\n",
    "\n",
    "            #plot the loss curve over time as the model trained\n",
    "            plt.figure(figsize=(10, 5))\n",
    "            plt.plot(train_losses, label='Training Loss', color='blue')\n",
    "            plt.xlabel('Batch (x2000)')\n",
    "            plt.ylabel('Loss')\n",
    "            plt.title('Training Loss Over Time')\n",
    "            plt.legend()\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            plt.show()       \n",
    "\n",
    "        # Plot per-class accuracy if enabled\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.bar(test_class_accuracies.keys(), test_class_accuracies.values(), color='blue')\n",
    "        plt.xlabel(\"Classes\")\n",
    "        plt.ylabel(\"Accuracy (%)\")\n",
    "        plt.title(\"Model Accuracy Per Class\")\n",
    "        plt.xticks(rotation=45)  # Rotate class names for readability\n",
    "        plt.ylim(0, 100)  # Set y-axis range to 0-100%\n",
    "        plt.show()\n",
    "\n",
    "        # print per-class accuracy\n",
    "        for classname, accuracy in test_class_accuracies():\n",
    "            print(f'Accuracy for class {classname:5s}: {accuracy:.1f}%')\n",
    "\n",
    "    # Return all results in a dictionary\n",
    "    results = {\n",
    "        \"train_losses\": train_losses,\n",
    "        \"train_accuracies\": train_accuracies,\n",
    "        \"test_accuracies\": test_accuracies,\n",
    "        \"test_class_accuracies\": test_class_accuracies,\n",
    "        \"final_test_accuracy\": final_test_accuracy,\n",
    "        \"total_time\": total_time\n",
    "    }\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Comparitive Analysis and Results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base model results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model, optimizer, and loss function\n",
    "base = CNN()\n",
    "optimizer = optim.Adam(base.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "train_nn(base, trainloader, criterion, optimizer, epochs=2, use_gpu=True)\n",
    "print(\"Base accuracy: \", test_nn(testloader, base, use_gpu=True))\n",
    "\n",
    "# evaluate the base model\n",
    "base_results = evaluate_model(base, trainloader, testloader, classes, epochs=5, use_gpu=True, show_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Batch: 2000, Avg. Loss: 1.8923\n",
      "Epoch: 0, Batch: 4000, Avg. Loss: 1.6340\n",
      "Epoch: 0, Batch: 6000, Avg. Loss: 1.5270\n",
      "Epoch: 0, Batch: 8000, Avg. Loss: 1.4762\n",
      "Epoch: 0, Batch: 10000, Avg. Loss: 1.4367\n",
      "Epoch: 0, Batch: 12000, Avg. Loss: 1.3894\n",
      "Epoch: 1, Batch: 2000, Avg. Loss: 1.3183\n",
      "Epoch: 1, Batch: 4000, Avg. Loss: 1.3230\n",
      "Epoch: 1, Batch: 6000, Avg. Loss: 1.3334\n",
      "Epoch: 1, Batch: 8000, Avg. Loss: 1.3256\n",
      "Epoch: 1, Batch: 10000, Avg. Loss: 1.2845\n",
      "Epoch: 1, Batch: 12000, Avg. Loss: 1.3001\n",
      "Finished Training\n",
      "Overall Model Accuracy: 52.63%\n",
      "Base accuracy:  52.63\n",
      "\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cross_entropy_loss(): argument 'input' (position 1) must be Tensor, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[70], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBase accuracy: \u001b[39m\u001b[38;5;124m\"\u001b[39m, test_nn_lenet(LeNet5_base, testloader, use_gpu\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m))\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# evaluate the base model\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m LeNet5_base_results \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mLeNet5_base\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtestloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclasses\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_gpu\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[67], line 45\u001b[0m, in \u001b[0;36mevaluate_model\u001b[1;34m(model, trainloader, testloader, classes, epochs, use_gpu, show_graph, tain)\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# Train the model for one epoch\u001b[39;00m\n\u001b[1;32m---> 45\u001b[0m train_loss, train_time \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_nn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimiser\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_gpu\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_gpu\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     46\u001b[0m total_time \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m train_time\n\u001b[0;32m     48\u001b[0m \u001b[38;5;66;03m# Test the model after training\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[58], line 35\u001b[0m, in \u001b[0;36mtrain_nn\u001b[1;34m(model, trainloader, criterion, optimizer, epochs, use_gpu)\u001b[0m\n\u001b[0;32m     32\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()  \u001b[38;5;66;03m# Reset gradients\u001b[39;00m\n\u001b[0;32m     34\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(inputs)  \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[1;32m---> 35\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Compute loss\u001b[39;00m\n\u001b[0;32m     37\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()  \u001b[38;5;66;03m# Backpropagation\u001b[39;00m\n\u001b[0;32m     38\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()  \u001b[38;5;66;03m# Update weights\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Emman\\anaconda3\\envs\\newEnv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Emman\\anaconda3\\envs\\newEnv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\Emman\\anaconda3\\envs\\newEnv\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:1293\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m   1292\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m-> 1293\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1294\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1295\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1296\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1297\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1298\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1299\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1300\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Emman\\anaconda3\\envs\\newEnv\\Lib\\site-packages\\torch\\nn\\functional.py:3479\u001b[0m, in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[0;32m   3477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3478\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[1;32m-> 3479\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3480\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3481\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3482\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3483\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3484\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3485\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3486\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: cross_entropy_loss(): argument 'input' (position 1) must be Tensor, not tuple"
     ]
    }
   ],
   "source": [
    "# Define model, optimizer, and loss function\n",
    "LeNet5_base = LeNet5(num_classes=10)\n",
    "optimizer = optim.Adam(LeNet5_base.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "train_nn_lenet(LeNet5_base, trainloader, criterion, optimizer, epochs=2, use_gpu=True)\n",
    "print(\"Base accuracy: \", test_nn_lenet(LeNet5_base, testloader, use_gpu=True))\n",
    "\n",
    "# evaluate the base model\n",
    "# LeNet5_base_results = evaluate_model(LeNet5_base, trainloader, testloader, classes, epochs=5, use_gpu=True, show_graph=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Genetic algorithm results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the number of generations\n",
    "generations = 2\n",
    "\n",
    "# Set the population size\n",
    "population_size = generations * 2\n",
    "\n",
    "# Set the mutation rate\n",
    "mutation_rate = 0.1\n",
    "\n",
    "# Set the number of epochs\n",
    "epochs = 5\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "# Run the Genetic Algorithm\n",
    "ga_results = run_genetic_algorithm(criterion, population_size, generations,trainloader,testloader,epochs,mutation_rate)\n",
    "\n",
    "# Access results\n",
    "ga_best_model = ga_results[\"best_model\"]\n",
    "generation_times = ga_results[\"generation_times\"]\n",
    "best_accuracies = ga_results[\"best_accuracies\"]\n",
    "\n",
    "# Print summary\n",
    "print(f\"\\nFinal Best Model Accuracy: {best_accuracies[-1]:.2f}%\")\n",
    "print(f\"Time Taken Per Generation: {generation_times}\")\n",
    "\n",
    "# save the best model\n",
    "torch.save(ga_best_model.state_dict(), 'best_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot a graph of the best accuracies\n",
    "plt.plot(best_accuracies)\n",
    "plt.xlabel('Generation')\n",
    "plt.ylabel('Best Accuracy')\n",
    "plt.title('Best Accuracy vs Generation')\n",
    "plt.show()\n",
    "\n",
    "#plot a graph of the generation times\n",
    "plt.plot(generation_times)\n",
    "plt.xlabel('Generation')\n",
    "plt.ylabel('Time (s)')\n",
    "plt.title('Generation Time')\n",
    "plt.show()\n",
    "\n",
    "# evaluate the genetic algotithm's best model\n",
    "ga_best_model_results = evaluate_model(ga_best_model, trainloader, testloader, classes, epochs=5, use_gpu=True, show_graph=True, tain = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimized Genetic algorithma results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Conclusion\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Tutorial comparison\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## References\n",
    "\n",
    "\n",
    "source [1] : https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html \n",
    "source [2] : https://www.geeksforgeeks.org/how-to-implement-genetic-algorithm-using-pytorch/ "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
